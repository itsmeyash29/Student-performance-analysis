{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "id": "jUhL6btIq7nc",
    "outputId": "6ec0d05f-a469-454d-b076-18bcdafebccb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "executionInfo": {
     "elapsed": 19804,
     "status": "ok",
     "timestamp": 1705566442253,
     "user": {
      "displayName": "Yash javali",
      "userId": "16306812349754871373"
     },
     "user_tz": -330
    },
    "id": "WIxUKtttrYeT",
    "outputId": "928a3311-a70f-4059-b2dd-639bad5b5608",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2385451385.py, line 95)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\91807\\AppData\\Local\\Temp\\ipykernel_19040\\2385451385.py\"\u001b[1;36m, line \u001b[1;32m95\u001b[0m\n\u001b[1;33m    data = data.drop(\"gender\", axis=1)k\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import time as t\n",
    "import sklearn.utils as u\n",
    "import sklearn.preprocessing as pp\n",
    "import sklearn.tree as tr\n",
    "import sklearn.ensemble as es\n",
    "import sklearn.metrics as m\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.neural_network as nn\n",
    "import numpy as np\n",
    "#import random as rnd\n",
    "import warnings as w\n",
    "w.filterwarnings('ignore')\n",
    "\n",
    "#loading the CSV File\n",
    "data = pd.read_csv(\"DM-Data.csv\")\n",
    "\n",
    "#user interaction loop creation for differnt graphsThis \n",
    "#section presents a menu to the user where they can choose various options \n",
    "#related to plotting graphs. The loop continues until the user enters the choice 10 to exit.\n",
    "ch = 0\n",
    "while(ch != 10):\n",
    "    print(\"1.Marks Class Count Graph\\t2.Marks Class Semester-wise Graph\\n3.Marks Class Gender-wise Graph\\t4.Marks Class Nationality-wise Graph\\n5.Marks Class Grade-wise Graph\\t6.Marks Class Section-wise Graph\\n7.Marks Class Topic-wise Graph\\t8.Marks Class Stage-wise Graph\\n9.Marks Class Absent Days-wise\\t10.No Graph\\n\")\n",
    "    ch = int(input(\"Enter Choice: \"))\n",
    "    if (ch == 1):\n",
    "        print(\"Loading Graph....\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Count Graph\")\n",
    "        axes = sb.countplot(x='Class', data=data, order=['L', 'M', 'H'])\n",
    "        plt.show()\n",
    "    elif (ch == 2):\n",
    "        print(\"Loading Graph....\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Semester-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='Semester', hue='Class', data=data, hue_order=['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 3):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Gender-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='gender', hue='Class', data=data, order=['M', 'F'], hue_order=['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 4):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Nationality-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='NationalITy', hue='Class', data=data, hue_order=['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 5):\n",
    "        print(\"Loading Graph: \\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Grade-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='GradeID', hue='Class', data=data, order=['G-02', 'G-04', 'G-05', 'G-06', 'G-07', 'G-08', 'G-09', 'G-10', 'G-11', 'G-12'], hue_order = ['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch ==6):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Section-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='SectionID', hue='Class', data=data, hue_order = ['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 7):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Topic-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='Topic', hue='Class', data=data, hue_order = ['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 8):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Stage-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='StageID', hue='Class', data=data, hue_order = ['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 9):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Absent Days-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='StudentAbsenceDays', hue='Class', data=data, hue_order = ['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "if(ch == 10):\n",
    "    print(\"Exiting..\\n\")\n",
    "    t.sleep(1)\n",
    "#cor = data.corr()\n",
    "#print(cor)\n",
    "data = data.drop(\"gender\", axis=1)k\n",
    "data = data.drop(\"StageID\", axis=1)\n",
    "data = data.drop(\"GradeID\", axis=1)\n",
    "data = data.drop(\"NationalITy\", axis=1)\n",
    "data = data.drop(\"PlaceofBirth\", axis=1)\n",
    "data = data.drop(\"SectionID\", axis=1)\n",
    "data = data.drop(\"Topic\", axis=1)\n",
    "data = data.drop(\"Semester\", axis=1)\n",
    "data = data.drop(\"Relation\", axis=1)\n",
    "data = data.drop(\"ParentschoolSatisfaction\", axis=1)\n",
    "data = data.drop(\"ParentAnsweringSurvey\", axis=1)\n",
    "#data = data.drop(\"VisITedResources\", axis=1)\n",
    "data = data.drop(\"AnnouncementsView\", axis=1)\n",
    "u.shuffle(data)\n",
    "countD = 0\n",
    "countP = 0\n",
    "countL = 0\n",
    "countR = 0\n",
    "countN = 0\n",
    "gradeID_dict = {\"G-01\" : 1,\n",
    "                \"G-02\" : 2,\n",
    "                \"G-03\" : 3,\n",
    "                \"G-04\" : 4,\n",
    "                \"G-05\" : 5,\n",
    "                \"G-06\" : 6,\n",
    "                \"G-07\" : 7,\n",
    "                \"G-08\" : 8,\n",
    "                \"G-09\" : 9,\n",
    "                \"G-10\" : 10,\n",
    "                \"G-11\" : 11,\n",
    "                \"G-12\" : 12}\n",
    "data = data.replace({\"GradeID\" : gradeID_dict})\n",
    "#sig = []\n",
    "#MACHINE LEARNING MODELS\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == type(object):\n",
    "        le = pp.LabelEncoder()\n",
    "        data[column] = le.fit_transform(data[column])\n",
    "        #SPLITTING DATA INTO TRAINING AND TESTING SETS, Training machine learning models \n",
    "        #(Decision Tree, Random Forest, Perceptron, Logistic Regression\n",
    "ind = int(len(data) * 0.70)\n",
    "feats = data.values[:, 0:4]\n",
    "lbls = data.values[:,4]\n",
    "feats_Train = feats[0:ind]\n",
    "feats_Test = feats[(ind+1):len(feats)]\n",
    "lbls_Train = lbls[0:ind]\n",
    "lbls_Test = lbls[(ind+1):len(lbls)]\n",
    "modelD = tr.DecisionTreeClassifier()\n",
    "modelD.fit(feats_Train, lbls_Train)\n",
    "lbls_predD = modelD.predict(feats_Test)\n",
    "for a,b in zip(lbls_Test, lbls_predD):\n",
    "    if(a==b):\n",
    "        countD += 1\n",
    "accD = (countD/len(lbls_Test))\n",
    "print(\"\\nAccuracy measures using Decision Tree:\")\n",
    "print(m.classification_report(lbls_Test, lbls_predD),\"\\n\")\n",
    "print(\"\\nAccuracy using Decision Tree: \", str(round(accD, 3)))\n",
    "t.sleep(1)\n",
    "modelR = es.RandomForestClassifier()\n",
    "modelR.fit(feats_Train, lbls_Train)\n",
    "lbls_predR = modelR.predict(feats_Test)\n",
    "for a,b in zip(lbls_Test, lbls_predR):\n",
    "    if(a==b):\n",
    "        countR += 1\n",
    "print(\"\\nAccuracy Measures for Random Forest Classifier: \\n\")\n",
    "#print(\"\\nConfusion Matrix: \\n\", m.confusion_matrix(lbls_Test, lbls_predR))\n",
    "print(\"\\n\", m.classification_report(lbls_Test,lbls_predR))\n",
    "accR = countR/len(lbls_Test)\n",
    "print(\"\\nAccuracy using Random Forest: \", str(round(accR, 3)))\n",
    "t.sleep(1)\n",
    "modelP = lm.Perceptron()\n",
    "modelP.fit(feats_Train, lbls_Train)\n",
    "lbls_predP = modelP.predict(feats_Test)\n",
    "for a,b in zip(lbls_Test, lbls_predP):\n",
    "    if a == b:\n",
    "        countP += 1\n",
    "accP = countP/len(lbls_Test)\n",
    "print(\"\\nAccuracy measures using Linear Model Perceptron:\")\n",
    "print(m.classification_report(lbls_Test, lbls_predP),\"\\n\")\n",
    "print(\"\\nAccuracy using Linear Model Perceptron: \", str(round(accP, 3)), \"\\n\")\n",
    "t.sleep(1)\n",
    "modelL = lm.LogisticRegression()\n",
    "modelL.fit(feats_Train, lbls_Train)\n",
    "lbls_predL = modelL.predict(feats_Test)\n",
    "for a,b in zip(lbls_Test, lbls_predL):\n",
    "    if a == b:\n",
    "        countL += 1\n",
    "accL = countL/len(lbls_Test)\n",
    "print(\"\\nAccuracy measures using Linear Model Logistic Regression:\")\n",
    "print(m.classification_report(lbls_Test, lbls_predL),\"\\n\")\n",
    "print(\"\\nAccuracy using Linear Model Logistic Regression: \", str(round(accP, 3)), \"\\n\")\n",
    "t.sleep(1)\n",
    "modelN = nn.MLPClassifier(activation=\"logistic\")\n",
    "modelN.fit(feats_Train, lbls_Train)\n",
    "lbls_predN = modelN.predict(feats_Test)\n",
    "for a,b in zip(lbls_Test, lbls_predN):\n",
    "    #sig.append(1/(1+ np.exp(-b)))\n",
    "    if a==b:\n",
    "        countN += 1\n",
    "#print(\"\\nAverage value of Sigmoid Function: \", str(round(np.average(sig), 3)))\n",
    "print(\"\\nAccuracy measures using MLP Classifier:\")\n",
    "print(m.classification_report(lbls_Test, lbls_predN),\"\\n\")\n",
    "accN = countN/len(lbls_Test)\n",
    "print(\"\\nAccuracy using Neural Network MLP Classifier: \", str(round(accN, 3)), \"\\n\")\n",
    "choice = input(\"Do you want to test specific input (y or n): \")\n",
    "if(choice.lower()==\"y\"):\n",
    "    gen = input(\"Enter Gender (M or F): \")\n",
    "    if (gen.upper() == \"M\"):\n",
    "       gen = 1\n",
    "    elif (gen.upper() == \"F\"):\n",
    "       gen = 0\n",
    "    nat = input(\"Enter Nationality: \")\n",
    "    pob = input(\"Place of Birth: \")\n",
    "    gra = input(\"Grade ID as (G-<grade>): \")\n",
    "    if(gra == \"G-02\"):\n",
    "        gra = 2\n",
    "    elif (gra == \"G-04\"):\n",
    "        gra = 4\n",
    "    elif (gra == \"G-05\"):\n",
    "        gra = 5\n",
    "    elif (gra == \"G-06\"):\n",
    "        gra = 6\n",
    "    elif (gra == \"G-07\"):\n",
    "        gra = 7\n",
    "    elif (gra == \"G-08\"):\n",
    "        gra = 8\n",
    "    elif (gra == \"G-09\"):\n",
    "        gra = 9\n",
    "    elif (gra == \"G-10\"):\n",
    "        gra = 10\n",
    "    elif (gra == \"G-11\"):\n",
    "        gra = 11\n",
    "    elif (gra == \"G-12\"):\n",
    "        gra = 12\n",
    "    sec = input(\"Enter Section: \")\n",
    "    top = input(\"Enter Topic: \")\n",
    "    sem = input(\"Enter Semester (F or S): \")\n",
    "    if (sem.upper() == \"F\"):\n",
    "       sem = 0\n",
    "    elif (sem.upper() == \"S\"):\n",
    "       sem = 1\n",
    "    rel = input(\"Enter Relation (Father or Mum): \")\n",
    "    if (rel == \"Father\"):\n",
    "       rel = 0\n",
    "    elif (rel == \"Mum\"):\n",
    "       rel = 1\n",
    "    rai = int(input(\"Enter raised hands: \"))\n",
    "    res = int(input(\"Enter Visited Resources: \"))\n",
    "    ann = int(input(\"Enter announcements viewed: \"))\n",
    "    dis = int(input(\"Enter no. of Discussions: \"))\n",
    "    sur = input(\"Enter Parent Answered Survey (Y or N): \")\n",
    "    if (sur.upper() == \"Y\"):\n",
    "       sur = 1\n",
    "    elif (sur.upper() == \"N\"):\n",
    "       sur = 0\n",
    "    sat = input(\"Enter Parent School Satisfaction (Good or Bad): \")\n",
    "    if (sat == \"Good\"):\n",
    "       sat = 1\n",
    "    elif (sat == \"Bad\"):\n",
    "       sat = 0\n",
    "    absc = input(\"Enter No. of Abscenes(Under-7 or Above-7): \")\n",
    "    if (absc == \"Under-7\"):\n",
    "       absc = 1\n",
    "    elif (absc == \"Above-7\"):\n",
    "       absc = 0\n",
    "    arr = np.array([rai, res, dis, absc])\n",
    "    #arr = np.array([gen, rnd.randint(0, 30), rnd.randint(0, 30), sta, gra, rnd.randint(0, 30), rnd.randint(0, 30), sem, rel, rai, res, ann, dis, sur, sat, absc])\n",
    "    predD = modelD.predict(arr.reshape(1, -1))\n",
    "    predR = modelR.predict(arr.reshape(1, -1))\n",
    "    predP = modelP.predict(arr.reshape(1, -1))\n",
    "    predL = modelL.predict(arr.reshape(1, -1))\n",
    "    predN = modelN.predict(arr.reshape(1, -1))\n",
    "    if (predD == 0):\n",
    "        predD = \"H\"\n",
    "    elif (predD == 1):\n",
    "        predD = \"M\"\n",
    "    elif (predD == 2):\n",
    "        predD = \"L\"\n",
    "    if (predR == 0):\n",
    "        predR = \"H\"\n",
    "    elif (predR == 1):\n",
    "        predR = \"M\"\n",
    "    elif (predR == 2):\n",
    "        predR = \"L\"\n",
    "    if (predP == 0):\n",
    "        predP = \"H\"\n",
    "    elif (predP == 1):\n",
    "        predP = \"M\"\n",
    "    elif (predP == 2):\n",
    "        predP = \"L\"\n",
    "    if (predL == 0):\n",
    "        predL = \"H\"\n",
    "    elif (predL == 1):\n",
    "        predL = \"M\"\n",
    "    elif (predL == 2):\n",
    "        predL = \"L\"\n",
    "    if (predN == 0):\n",
    "        predN = \"H\"\n",
    "    elif (predN == 1):\n",
    "        predN = \"M\"\n",
    "    elif (predN == 2):\n",
    "        predN = \"L\"\n",
    "    t.sleep(1)\n",
    "    print(\"\\nUsing Decision Tree Classifier: \", predD)\n",
    "    t.sleep(1)\n",
    "    print(\"Using Random Forest Classifier: \", predR)\n",
    "    t.sleep(1)\n",
    "    print(\"Using Linear Model Perceptron: \", predP)\n",
    "    t.sleep(1)\n",
    "    print(\"Using Linear Model Logisitic Regression: \", predL)\n",
    "    t.sleep(1)\n",
    "    print(\"Using Neural Network MLP Classifier: \", predN)\n",
    "    print(\"\\nExiting...\")\n",
    "    t.sleep(1)\n",
    "else:\n",
    "    print(\"Exiting..\")\n",
    "    t.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Marks Class Count Graph\t2.Marks Class Semester-wise Graph\n",
      "3.Marks Class Gender-wise Graph\t4.Marks Class Nationality-wise Graph\n",
      "5.Marks Class Grade-wise Graph\t6.Marks Class Section-wise Graph\n",
      "7.Marks Class Topic-wise Graph\t8.Marks Class Stage-wise Graph\n",
      "9.Marks Class Absent Days-wise\t10.No Graph\n",
      "\n",
      "Enter Choice: 8\n",
      "Loading Graph..\n",
      "\n",
      "\tMarks Class Stage-wise Graph\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Marks Class Count Graph\t2.Marks Class Semester-wise Graph\n",
      "3.Marks Class Gender-wise Graph\t4.Marks Class Nationality-wise Graph\n",
      "5.Marks Class Grade-wise Graph\t6.Marks Class Section-wise Graph\n",
      "7.Marks Class Topic-wise Graph\t8.Marks Class Stage-wise Graph\n",
      "9.Marks Class Absent Days-wise\t10.No Graph\n",
      "\n",
      "Enter Choice: 10\n",
      "Exiting..\n",
      "\n",
      "\n",
      "Accuracy measures using Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58        52\n",
      "           1       0.89      0.86      0.87        28\n",
      "           2       0.59      0.57      0.58        63\n",
      "\n",
      "    accuracy                           0.64       143\n",
      "   macro avg       0.68      0.67      0.68       143\n",
      "weighted avg       0.64      0.64      0.64       143\n",
      " \n",
      "\n",
      "\n",
      "Accuracy using Decision Tree:  0.636\n",
      "\n",
      "Accuracy Measures for Random Forest Classifier: \n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68        52\n",
      "           1       0.93      0.93      0.93        28\n",
      "           2       0.71      0.63      0.67        63\n",
      "\n",
      "    accuracy                           0.73       143\n",
      "   macro avg       0.76      0.76      0.76       143\n",
      "weighted avg       0.73      0.73      0.73       143\n",
      "\n",
      "\n",
      "Accuracy using Random Forest:  0.727\n",
      "\n",
      "Accuracy measures using Linear Model Perceptron:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57        52\n",
      "           1       1.00      0.14      0.25        28\n",
      "           2       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.39       143\n",
      "   macro avg       0.47      0.38      0.27       143\n",
      "weighted avg       0.34      0.39      0.26       143\n",
      " \n",
      "\n",
      "\n",
      "Accuracy using Linear Model Perceptron:  0.392 \n",
      "\n",
      "\n",
      "Accuracy measures using Linear Model Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.85      0.75        52\n",
      "           1       0.93      0.89      0.91        28\n",
      "           2       0.78      0.62      0.69        63\n",
      "\n",
      "    accuracy                           0.76       143\n",
      "   macro avg       0.79      0.79      0.78       143\n",
      "weighted avg       0.77      0.76      0.75       143\n",
      " \n",
      "\n",
      "\n",
      "Accuracy using Linear Model Logistic Regression:  0.392 \n",
      "\n",
      "\n",
      "Accuracy measures using MLP Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70        52\n",
      "           1       0.92      0.86      0.89        28\n",
      "           2       0.72      0.54      0.62        63\n",
      "\n",
      "    accuracy                           0.71       143\n",
      "   macro avg       0.75      0.74      0.74       143\n",
      "weighted avg       0.72      0.71      0.70       143\n",
      " \n",
      "\n",
      "\n",
      "Accuracy using Neural Network MLP Classifier:  0.706 \n",
      "\n",
      "Do you want to test specific input (y or n): y\n",
      "Enter Gender (M or F): M\n",
      "Enter Nationality: KW\n",
      "Place of Birth: KuwaIT\n",
      "Grade ID as (G-<grade>): G-04\n",
      "Enter Section: A\n",
      "Enter Topic: IT\n",
      "Enter Semester (F or S): F\n",
      "Enter Relation (Father or Mum): Father\n",
      "Enter raised hands: 15\n",
      "Enter Visited Resources: 16\n",
      "Enter announcements viewed: 2\n",
      "Enter no. of Discussions: 20\n",
      "Enter Parent Answered Survey (Y or N): Y\n",
      "Enter Parent School Satisfaction (Good or Bad): Good\n",
      "Enter No. of Abscenes(Under-7 or Above-7): Under-7\n",
      "\n",
      "Using Decision Tree Classifier:  L\n",
      "Using Random Forest Classifier:  L\n",
      "Using Linear Model Perceptron:  H\n",
      "Using Linear Model Logisitic Regression:  L\n",
      "Using Neural Network MLP Classifier:  L\n",
      "\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import time as t\n",
    "import sklearn.utils as u\n",
    "import sklearn.preprocessing as pp\n",
    "import sklearn.tree as tr\n",
    "import sklearn.ensemble as es\n",
    "import sklearn.metrics as m\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.neural_network as nn\n",
    "import numpy as np\n",
    "#import random as rnd\n",
    "import warnings as w\n",
    "w.filterwarnings('ignore')\n",
    "\n",
    "#loading the CSV File\n",
    "data = pd.read_csv(\"AI-Data.csv\")\n",
    "\n",
    "#user interaction loop creation for differnt graphsThis \n",
    "#section presents a menu to the user where they can choose various options \n",
    "#related to plotting graphs. The loop continues until the user enters the choice 10 to exit.\n",
    "ch = 0\n",
    "while(ch != 10):\n",
    "    print(\"1.Marks Class Count Graph\\t2.Marks Class Semester-wise Graph\\n3.Marks Class Gender-wise Graph\\t4.Marks Class Nationality-wise Graph\\n5.Marks Class Grade-wise Graph\\t6.Marks Class Section-wise Graph\\n7.Marks Class Topic-wise Graph\\t8.Marks Class Stage-wise Graph\\n9.Marks Class Absent Days-wise\\t10.No Graph\\n\")\n",
    "    ch = int(input(\"Enter Choice: \"))\n",
    "    if (ch == 1):\n",
    "        print(\"Loading Graph....\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Count Graph\")\n",
    "        axes = sb.countplot(x='Class', data=data, order=['L', 'M', 'H'])\n",
    "        plt.show()\n",
    "    elif (ch == 2):\n",
    "        print(\"Loading Graph....\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Semester-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='Semester', hue='Class', data=data, hue_order=['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 3):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Gender-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='gender', hue='Class', data=data, order=['M', 'F'], hue_order=['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 4):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Nationality-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='NationalITy', hue='Class', data=data, hue_order=['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 5):\n",
    "        print(\"Loading Graph: \\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Grade-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='GradeID', hue='Class', data=data, order=['G-02', 'G-04', 'G-05', 'G-06', 'G-07', 'G-08', 'G-09', 'G-10', 'G-11', 'G-12'], hue_order = ['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch ==6):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Section-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='SectionID', hue='Class', data=data, hue_order = ['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 7):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Topic-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='Topic', hue='Class', data=data, hue_order = ['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 8):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Stage-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='StageID', hue='Class', data=data, hue_order = ['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "    elif (ch == 9):\n",
    "        print(\"Loading Graph..\\n\")\n",
    "        t.sleep(1)\n",
    "        print(\"\\tMarks Class Absent Days-wise Graph\")\n",
    "        fig, axesarr = plt.subplots(1, figsize=(10, 6))\n",
    "        sb.countplot(x='StudentAbsenceDays', hue='Class', data=data, hue_order = ['L', 'M', 'H'], axes=axesarr)\n",
    "        plt.show()\n",
    "if(ch == 10):\n",
    "    print(\"Exiting..\\n\")\n",
    "    t.sleep(1)\n",
    "#cor = data.corr()\n",
    "#print(cor)\n",
    "data = data.drop(\"gender\", axis=1)\n",
    "data = data.drop(\"StageID\", axis=1)\n",
    "data = data.drop(\"GradeID\", axis=1)\n",
    "data = data.drop(\"NationalITy\", axis=1)\n",
    "data = data.drop(\"PlaceofBirth\", axis=1)\n",
    "data = data.drop(\"SectionID\", axis=1)\n",
    "data = data.drop(\"Topic\", axis=1)\n",
    "data = data.drop(\"Semester\", axis=1)\n",
    "data = data.drop(\"Relation\", axis=1)\n",
    "data = data.drop(\"ParentschoolSatisfaction\", axis=1)\n",
    "data = data.drop(\"ParentAnsweringSurvey\", axis=1)\n",
    "#data = data.drop(\"VisITedResources\", axis=1)\n",
    "data = data.drop(\"AnnouncementsView\", axis=1)\n",
    "u.shuffle(data)\n",
    "countD = 0\n",
    "countP = 0\n",
    "countL = 0\n",
    "countR = 0\n",
    "countN = 0\n",
    "gradeID_dict = {\"G-01\" : 1,\n",
    "                \"G-02\" : 2,\n",
    "                \"G-03\" : 3,\n",
    "                \"G-04\" : 4,\n",
    "                \"G-05\" : 5,\n",
    "                \"G-06\" : 6,\n",
    "                \"G-07\" : 7,\n",
    "                \"G-08\" : 8,\n",
    "                \"G-09\" : 9,\n",
    "                \"G-10\" : 10,\n",
    "                \"G-11\" : 11,\n",
    "                \"G-12\" : 12}\n",
    "data = data.replace({\"GradeID\" : gradeID_dict})\n",
    "#sig = []\n",
    "#MACHINE LEARNING MODELS\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == type(object):\n",
    "        le = pp.LabelEncoder()\n",
    "        data[column] = le.fit_transform(data[column])\n",
    "        #SPLITTING DATA INTO TRAINING AND TESTING SETS, Training machine learning models \n",
    "        #(Decision Tree, Random Forest, Perceptron, Logistic Regression\n",
    "ind = int(len(data) * 0.70)\n",
    "feats = data.values[:, 0:4]\n",
    "lbls = data.values[:,4]\n",
    "feats_Train = feats[0:ind]\n",
    "feats_Test = feats[(ind+1):len(feats)]\n",
    "lbls_Train = lbls[0:ind]\n",
    "lbls_Test = lbls[(ind+1):len(lbls)]\n",
    "modelD = tr.DecisionTreeClassifier()\n",
    "modelD.fit(feats_Train, lbls_Train)\n",
    "lbls_predD = modelD.predict(feats_Test)\n",
    "for a,b in zip(lbls_Test, lbls_predD):\n",
    "    if(a==b):\n",
    "        countD += 1\n",
    "accD = (countD/len(lbls_Test))\n",
    "print(\"\\nAccuracy measures using Decision Tree:\")\n",
    "print(m.classification_report(lbls_Test, lbls_predD),\"\\n\")\n",
    "print(\"\\nAccuracy using Decision Tree: \", str(round(accD, 3)))\n",
    "t.sleep(1)\n",
    "modelR = es.RandomForestClassifier()\n",
    "modelR.fit(feats_Train, lbls_Train)\n",
    "lbls_predR = modelR.predict(feats_Test)\n",
    "for a,b in zip(lbls_Test, lbls_predR):\n",
    "    if(a==b):\n",
    "        countR += 1\n",
    "print(\"\\nAccuracy Measures for Random Forest Classifier: \\n\")\n",
    "#print(\"\\nConfusion Matrix: \\n\", m.confusion_matrix(lbls_Test, lbls_predR))\n",
    "print(\"\\n\", m.classification_report(lbls_Test,lbls_predR))\n",
    "accR = countR/len(lbls_Test)\n",
    "print(\"\\nAccuracy using Random Forest: \", str(round(accR, 3)))\n",
    "t.sleep(1)\n",
    "modelP = lm.Perceptron()\n",
    "modelP.fit(feats_Train, lbls_Train)\n",
    "lbls_predP = modelP.predict(feats_Test)\n",
    "for a,b in zip(lbls_Test, lbls_predP):\n",
    "    if a == b:\n",
    "        countP += 1\n",
    "accP = countP/len(lbls_Test)\n",
    "print(\"\\nAccuracy measures using Linear Model Perceptron:\")\n",
    "print(m.classification_report(lbls_Test, lbls_predP),\"\\n\")\n",
    "print(\"\\nAccuracy using Linear Model Perceptron: \", str(round(accP, 3)), \"\\n\")\n",
    "t.sleep(1)\n",
    "modelL = lm.LogisticRegression()\n",
    "modelL.fit(feats_Train, lbls_Train)\n",
    "lbls_predL = modelL.predict(feats_Test)\n",
    "for a,b in zip(lbls_Test, lbls_predL):\n",
    "    if a == b:\n",
    "        countL += 1\n",
    "accL = countL/len(lbls_Test)\n",
    "print(\"\\nAccuracy measures using Linear Model Logistic Regression:\")\n",
    "print(m.classification_report(lbls_Test, lbls_predL),\"\\n\")\n",
    "print(\"\\nAccuracy using Linear Model Logistic Regression: \", str(round(accP, 3)), \"\\n\")\n",
    "t.sleep(1)\n",
    "modelN = nn.MLPClassifier(activation=\"logistic\")\n",
    "modelN.fit(feats_Train, lbls_Train)\n",
    "lbls_predN = modelN.predict(feats_Test)\n",
    "for a,b in zip(lbls_Test, lbls_predN):\n",
    "    #sig.append(1/(1+ np.exp(-b)))\n",
    "    if a==b:\n",
    "        countN += 1\n",
    "#print(\"\\nAverage value of Sigmoid Function: \", str(round(np.average(sig), 3)))\n",
    "print(\"\\nAccuracy measures using MLP Classifier:\")\n",
    "print(m.classification_report(lbls_Test, lbls_predN),\"\\n\")\n",
    "accN = countN/len(lbls_Test)\n",
    "print(\"\\nAccuracy using Neural Network MLP Classifier: \", str(round(accN, 3)), \"\\n\")\n",
    "choice = input(\"Do you want to test specific input (y or n): \")\n",
    "if(choice.lower()==\"y\"):\n",
    "    gen = input(\"Enter Gender (M or F): \")\n",
    "    if (gen.upper() == \"M\"):\n",
    "       gen = 1\n",
    "    elif (gen.upper() == \"F\"):\n",
    "       gen = 0\n",
    "    nat = input(\"Enter Nationality: \")\n",
    "    pob = input(\"Place of Birth: \")\n",
    "    gra = input(\"Grade ID as (G-<grade>): \")\n",
    "    if(gra == \"G-02\"):\n",
    "        gra = 2\n",
    "    elif (gra == \"G-04\"):\n",
    "        gra = 4\n",
    "    elif (gra == \"G-05\"):\n",
    "        gra = 5\n",
    "    elif (gra == \"G-06\"):\n",
    "        gra = 6\n",
    "    elif (gra == \"G-07\"):\n",
    "        gra = 7\n",
    "    elif (gra == \"G-08\"):\n",
    "        gra = 8\n",
    "    elif (gra == \"G-09\"):\n",
    "        gra = 9\n",
    "    elif (gra == \"G-10\"):\n",
    "        gra = 10\n",
    "    elif (gra == \"G-11\"):\n",
    "        gra = 11\n",
    "    elif (gra == \"G-12\"):\n",
    "        gra = 12\n",
    "    sec = input(\"Enter Section: \")\n",
    "    top = input(\"Enter Topic: \")\n",
    "    sem = input(\"Enter Semester (F or S): \")\n",
    "    if (sem.upper() == \"F\"):\n",
    "       sem = 0\n",
    "    elif (sem.upper() == \"S\"):\n",
    "       sem = 1\n",
    "    rel = input(\"Enter Relation (Father or Mum): \")\n",
    "    if (rel == \"Father\"):\n",
    "       rel = 0\n",
    "    elif (rel == \"Mum\"):\n",
    "       rel = 1\n",
    "    rai = int(input(\"Enter raised hands: \"))\n",
    "    res = int(input(\"Enter Visited Resources: \"))\n",
    "    ann = int(input(\"Enter announcements viewed: \"))\n",
    "    dis = int(input(\"Enter no. of Discussions: \"))\n",
    "    sur = input(\"Enter Parent Answered Survey (Y or N): \")\n",
    "    if (sur.upper() == \"Y\"):\n",
    "       sur = 1\n",
    "    elif (sur.upper() == \"N\"):\n",
    "       sur = 0\n",
    "    sat = input(\"Enter Parent School Satisfaction (Good or Bad): \")\n",
    "    if (sat == \"Good\"):\n",
    "       sat = 1\n",
    "    elif (sat == \"Bad\"):\n",
    "       sat = 0\n",
    "    absc = input(\"Enter No. of Abscenes(Under-7 or Above-7): \")\n",
    "    if (absc == \"Under-7\"):\n",
    "       absc = 1\n",
    "    elif (absc == \"Above-7\"):\n",
    "       absc = 0\n",
    "    arr = np.array([rai, res, dis, absc])\n",
    "    #arr = np.array([gen, rnd.randint(0, 30), rnd.randint(0, 30), sta, gra, rnd.randint(0, 30), rnd.randint(0, 30), sem, rel, rai, res, ann, dis, sur, sat, absc])\n",
    "    predD = modelD.predict(arr.reshape(1, -1))\n",
    "    predR = modelR.predict(arr.reshape(1, -1))\n",
    "    predP = modelP.predict(arr.reshape(1, -1))\n",
    "    predL = modelL.predict(arr.reshape(1, -1))\n",
    "    predN = modelN.predict(arr.reshape(1, -1))\n",
    "    if (predD == 0):\n",
    "        predD = \"H\"\n",
    "    elif (predD == 1):\n",
    "        predD = \"M\"\n",
    "    elif (predD == 2):\n",
    "        predD = \"L\"\n",
    "    if (predR == 0):\n",
    "        predR = \"H\"\n",
    "    elif (predR == 1):\n",
    "        predR = \"M\"\n",
    "    elif (predR == 2):\n",
    "        predR = \"L\"\n",
    "    if (predP == 0):\n",
    "        predP = \"H\"\n",
    "    elif (predP == 1):\n",
    "        predP = \"M\"\n",
    "    elif (predP == 2):\n",
    "        predP = \"L\"\n",
    "    if (predL == 0):\n",
    "        predL = \"H\"\n",
    "    elif (predL == 1):\n",
    "        predL = \"M\"\n",
    "    elif (predL == 2):\n",
    "        predL = \"L\"\n",
    "    if (predN == 0):\n",
    "        predN = \"H\"\n",
    "    elif (predN == 1):\n",
    "        predN = \"M\"\n",
    "    elif (predN == 2):\n",
    "        predN = \"L\"\n",
    "    t.sleep(1)\n",
    "    print(\"\\nUsing Decision Tree Classifier: \", predD)\n",
    "    t.sleep(1)\n",
    "    print(\"Using Random Forest Classifier: \", predR)\n",
    "    t.sleep(1)\n",
    "    print(\"Using Linear Model Perceptron: \", predP)\n",
    "    t.sleep(1)\n",
    "    print(\"Using Linear Model Logisitic Regression: \", predL)\n",
    "    t.sleep(1)\n",
    "    print(\"Using Neural Network MLP Classifier: \", predN)\n",
    "    print(\"\\nExiting...\")\n",
    "    t.sleep(1)\n",
    "else:\n",
    "    print(\"Exiting..\")\n",
    "    t.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM7BBV630KyTQe+khneVym0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
